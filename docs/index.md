# Курс «Программирование в ИИ"

## Детальный поурочный план

| Неделя | Занятие | Тема | Содержание |
| :--- | :--- | :--- | :--- |
| **1** | 1 | Введение. Исторический экскурс. | - |
|  | 2 | Экосистема ИИ-разработчика. | - |
| **2** | 3 | **Линейная алгебра в Python.** NumPy: Векторизация, Broadcast, Матричные операции. | Связь с Линалом (умножение матриц, транспонирование), оптимизация. |
|  | 4 | Pandas: Структуры данных, индексация, агрегация. EDA. | Чистка данных, обработка пропусков, `groupby`. |
| **3** | 5 | **Статистика в коде.** SciPy: Распределения, статистические тесты. | Понятие p-value, t-тест, корреляция. Визуализация (Seaborn). |
|  | 6 | **Градиентный спуск.** Производная, градиент. | Математический вывод, визуализация спуска. Learning Rate. |
| **4** | 7 | **Линейная регрессия.** Метод наименьших квадратов (OLS). Нормальное уравнение. | Математический вывод OLS, геометрический смысл. |
|  | 8 | Реализация Линейной регрессии с нуля на NumPy. | Сравнение с `sklearn.LinearRegression`, разбор ДЗ по градиенту. |
| **5** | 9 | **Логистическая регрессия.** Сигмоида. Функция потерь (Кросс-энтропия). | Математический вывод кросс-энтропии, бинарная классификация. |
|  | 10 | Регуляризация (L1, L2). Bias-Variance Tradeoff. | Математика регуляризации, подбор гиперпараметров. |
| **6** | 11 | **PCA (Метод главных компонент).** Собственные числа и векторы. | Математика PCA, сингулярное разложение. |
|  | 12 | **Метрики классификации.** Матрица ошибок, ROC-AUC, Precision/Recall. | Анализ несбалансированных данных. |
| **7** | 13 | **Кластеризация (K-Means).** Евклидово расстояние. DBSCAN. | Выбор оптимального K, метрики кластеризации. |
|  | 14 | **Промежуточный контроль.** | Обзор пройденного материала (NumPy, LogReg, Ансамбли). |
| **8** | 15 | **Введение в DL.** Нейрон, активация. **Backpropagation: Цепное правило.** | Математика Backprop, граф вычислений. |
|  | 16 | **Фреймворки DL.** PyTorch/TensorFlow: Тензоры, Autograd, GPU. | Сравнение фреймворков, архитектура DL-кода. |
| **9** | 17 | **MLP и Цикл обучения.** Loss, Optimizer (SGD, Adam), LR Schedulers. | Детальный разбор цикла обучения в PyTorch. |
|  | 18 | **CNN (Сверточные сети).** Свертка, Пулинг. Архитектуры (LeNet). | Локальное рецептивное поле, разделяемые веса. |
| **10** | 19 | **Продвинутые CNN.** ResNet, Inception. Transfer Learning. | Предобученные модели, аугментация. |
|  | 22 | **RNN/LSTM.** Проблема затухающего градиента. | Ячейка памяти LSTM. |
| **12** | 23 | **Трансформеры: Attention.** | Scaled Dot-Product, Self-Attention. |
|  | 24 | **Архитектура Трансформера.** Encoder/Decoder. | Позиционное кодирование. Обзор BERT, GPT. |
| **13** | 25 | **Продвинутые темы DL.** GANs. | Состязательное обучение, кейсы. |
|  | 26 | **Введение в RL.** Агент, Среда, Награда. | Q-Learning, DQN (обзор). |
| **14** | 27 | **Инженерия ML-систем.** MLOps: Docker, CI/CD. | Развертывание моделей, FastAPI. |
|  | 28 | **Этика и Безопасность ИИ.** XAI. | Fairness, Interpretability. |
| **15** | 29 | **Проектный семинар 1.** | Требования, структура отчёта. |
|  | 30 | **Проектный семинар 2.** | Разбор кейсов, Q&A. |
| **16** | 31 | **Проектный семинар 3.** | Промежуточный отчёт. |
|  | 32 | **Проектный семинар 4.** | Подготовка к защите. |
| **17–18** | 33–36 | Защита итоговых проектов | Доклады и ответы на вопросы. |

## Cписок домашних заданий

| № ДЗ | Неделя выдачи | Тема | Тип задания | Фокус проверки на практике |
| :--- | :--- | :--- | :--- | :--- |
| **ДЗ 1** | 1 | Инженерный старт | Настройка окружения, Git-flow, декоратор-таймер. | Практика 1 (Нед. 2): PEP8, Git-история. |
| **ДЗ 2** | 2 | Векторизация и EDA | Нормализация на NumPy. Базовый EDA. | Практика 2 (Нед. 3): Скорость векторизации. |
| **ДЗ 3** | 3 | Градиентный спуск | Реализация и визуализация. | Практика 3 (Нед. 4): Цепное правило, LR. |
| **ДЗ 4** | 4 | Линейная регрессия | OLS через нормальное уравнение (NumPy). | Практика 4 (Нед. 5): Геометрия OLS. |
| **ДЗ 5** | 5 | Логистическая регрессия | From scratch + L2. | Практика 5 (Нед. 6): Кросс-энтропия, регуляризация. |
| **ДЗ 6** | 6 | Метрики и PCA | Несбалансированность, PCA для визуализации. | Практика 6 (Нед. 7): ROC-AUC, порог. |
| **ДЗ 7** | 7 | Ансамблирование | RF и XGBoost, GridSearchCV. | Практика 7 (Нед. 8): Bagging/Boosting. |
| **ДЗ 8** | 9 | Backprop и PyTorch | Backprop на NumPy, простая MLP. | Практика 9 (Нед. 10): Autograd. |
